{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdfc7a6a",
   "metadata": {},
   "source": [
    "\n",
    "#### Assignment 2 (NLU 22)\n",
    "##### Word embeddings\n",
    "\n",
    "**Due 18, June 2022**  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff7a24",
   "metadata": {},
   "source": [
    "This assignment is about basic understnading of word embeddings and sequence to sequence modelling. It is divided into 2 parts. The first part consists of a report and some simple exercises with word vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e655bff",
   "metadata": {},
   "source": [
    "##### Word Embedding: introduction\n",
    "Let us recap what we know about word embedding from the lectures and labs.   \n",
    "1. A word embedding is a map from a vocabulary of tokens (words and phrases) to a vector space. This means that each word is mapped to a vector of fixed dimension. \n",
    "2. We can use \"similarity\" metrics in a vector space to reflect similarity between words. We will use *cosine* of the angle between two vectors as similarity metric. So the embedding must capture facts like the pairs (\"coffee\", \"cup\") are more similar than say, (\"coffee\", \"car\"). \n",
    "3. We set up a \"fake\" classification problem as follows:\n",
    "     1. given a fixed word *w*, every other word *w'* belongs to one of the 2 classes *close-to-w* or *not-close-to-w*\n",
    "     2. we train a neural model with some documents\n",
    "     3. what is of real interest are a set of weights in the model, not the solution. \n",
    "4. There are several approaches to the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f905bd",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "1. Write a survey report on the problem (about 2500 words without references). It should contain \n",
    "    1. an introduction and motivation to the problem\n",
    "    2. explanation of at least 2 of the several approaches (**skip-gram**, **continuous bag of words (CBOW)**, **global vectors** etc.)\n",
    "    3. some applications of word vectors in sequence-to-sequence modeling.   (**30** marks)\n",
    "    4. all references must be properly cited (see https://library.westernsydney.edu.au/main/sites/default/files/cite_Harvard.pdf) \n",
    "2. You will be provided with a file of 100-dimensional word vectors. Complete some simple exercises using these vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c77b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "# these are the libraries you might need. numpy, random will be needed\n",
    "# defaultdict will also prove useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14524c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##the following function reads from the file containing word-vectors \n",
    "# and stores in a dictionary. The key is the token and the value is the vector. \n",
    "# note this is not a csv file but ordinary, space-sperated text file\n",
    "# each line starts with the token followed by a 100-d vector\n",
    "#you should strip spaces, if any, at the beginning and end of lines \n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    pass\n",
    "#your code\n",
    "    return data\n",
    "# 5 marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8a2a1",
   "metadata": {},
   "source": [
    "*A word puzzle* \n",
    "1. king - man + woman ~ queen\n",
    "2. come up with 5 more such puzzles\n",
    "3. verify that the left-hand-side (king - man + woman) and right-hand-side (queen) are similar, see below. \n",
    "\n",
    "**5 marks** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc832fd",
   "metadata": {},
   "source": [
    "##### Similarity between word-vector-expressions \n",
    "1. Recall that each token (word/phrase etc.) is represnted by a vector.\n",
    "2. We measure the similarity of 2 vectors $\\pmb{x}$ and $\\pmb{y}$ by the *cosine* of the angle between them:\n",
    "$$ \\cos(\\pmb{x}, \\pmb{y}) \\equiv \\frac{\\pmb{x}\\centerdot\\pmb{y}}{|\\!|\\pmb{x}|\\!| |\\!|\\pmb{y}|\\!|} $$\n",
    "3. Here the \"dot product\" between two $n$-dimensional vectors $\\pmb{x}, \\pmb{y}$ is defined as \n",
    "$$\\pmb{x}\\centerdot\\pmb{y} = x_1y_1 + x_2y_2 + \\dotsb + x_ny_n $$\n",
    "4. and the length or norm of a vector $\\pmb{x}$ is \n",
    "$$|\\!|\\pmb{x}|\\!| = (x_1^2 +x_2^2 \\dotsb + x_n^2)^{1/2} = \\sqrt{x_1^2 +x_2^2 \\dotsb + x_n^2}$$ \n",
    "5. So to calculate, for example, similarity between *king - man + woman* and *woman* we find the corresponding vectors and measure their cosine similairy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e014af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete the following function and calculate the similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddca5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x and y are numpy 1-dimensional vectors\n",
    "def acos(x, y):\n",
    "    cs = 0\n",
    "    pass\n",
    "#your code, cs calculates the cosine of the angle between x and y. Update it.  \n",
    "return cs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526c331f",
   "metadata": {},
   "source": [
    "Calculate the cosine similirt between the word-expressions that you have given above.  \n",
    "\n",
    "**5 marks** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71836e08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
