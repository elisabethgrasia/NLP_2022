{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lab 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(gutenberg.raw()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import string\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "def tokenbuilder(txt):\n",
    "    #stem = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "    stem = PorterStemmer( mode = 'NLTK_EXTENSIONS')\n",
    "    txt = txt.lower()\n",
    "    rmv = [\"''\", \"'\", \"'s\", \"``\", \"`\", \"--\", \"__\"]\n",
    "    for token in nltk.word_tokenize(txt):\n",
    "        if token in string.punctuation or token in rmv:\n",
    "            if (token == r'.'):\n",
    "                token = r'</s>'\n",
    "            else:\n",
    "                continue\n",
    "        yield stem.stem(token)  \n",
    "        #yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenList(txt, stp = 0):\n",
    "    toke_list = [r'<b>']\n",
    "    if (stp == 0):\n",
    "        for token in tokenbuilder(gutenberg.raw(txt)):\n",
    "            toke_list.append(token)\n",
    "    else:\n",
    "         for token in tokenbuilder(gutenberg.raw(txt)):\n",
    "                if not token in stopWords:\n",
    "                    toke_list.append(token)\n",
    "    return toke_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create unigram\n",
    "from collections import defaultdict\n",
    "def uniGram(txt, st = 0, rfq = 0):\n",
    "    uniGm = defaultdict(list)\n",
    "    return uniGm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caes_unigm  = uniGram('shakespeare-caesar.txt')\n",
    "ham_unigm = uniGram('shakespeare-hamlet.txt')\n",
    "mac_unigm = uniGram('shakespeare-macbeth.txt')\n",
    "emma_unigm  = uniGram('austen-emma.txt')\n",
    "pers_unigm = uniGram('austen-persuasion.txt')\n",
    "sense_unigm = uniGram('austen-sense.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$6\\times 14$ matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight  []   []   [] \n",
      "\n",
      "blood  []   []   [] \n",
      "\n",
      "death  []   []   [] \n",
      "\n",
      "kill  []   []   [] \n",
      "\n",
      "hate  []   []   [] \n",
      "\n",
      "sword  []   []   [] \n",
      "\n",
      "sorrow  []   []   [] \n",
      "\n",
      "good  []   []   [] \n",
      "\n",
      "love  []   []   [] \n",
      "\n",
      "kind  []   []   [] \n",
      "\n",
      "happy  []   []   [] \n",
      "\n",
      "joy  []   []   [] \n",
      "\n",
      "forgive  []   []   [] \n",
      "\n",
      "peace  []   []   [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#try ot with some other words\n",
    "ls1 = ['fight', 'blood', 'death', 'kill', 'hate', 'sword', 'sorrow']\n",
    "ls2 = ['good', 'love', 'kind', 'happy', 'joy', 'forgive', 'peace']\n",
    "for w in ls1:\n",
    "    print(w + ' ', caes_unigm[w],' ', ham_unigm[w], ' ',  mac_unigm[w], '\\n')\n",
    "for w in ls2:\n",
    "    print(w + ' ', caes_unigm[w],' ', ham_unigm[w], ' ',  mac_unigm[w], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fight  []   []   [] \n",
      "\n",
      "blood  []   []   [] \n",
      "\n",
      "death  []   []   [] \n",
      "\n",
      "kill  []   []   [] \n",
      "\n",
      "hate  []   []   [] \n",
      "\n",
      "sword  []   []   [] \n",
      "\n",
      "sorrow  []   []   [] \n",
      "\n",
      "good  []   []   [] \n",
      "\n",
      "love  []   []   [] \n",
      "\n",
      "kind  []   []   [] \n",
      "\n",
      "happy  []   []   [] \n",
      "\n",
      "joy  []   []   [] \n",
      "\n",
      "forgive  []   []   [] \n",
      "\n",
      "peace  []   []   [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in ls1:\n",
    "    print(w + ' ', emma_unigm[w],' ', pers_unigm[w], ' ',  sense_unigm[w], '\\n')\n",
    "for w in ls2:\n",
    "    print(w + ' ', emma_unigm[w],' ', pers_unigm[w], ' ',  sense_unigm[w], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = np.array([313, 117, 76, 123])\n",
    "pers = np.array([170, 41, 20, 64])\n",
    "sense = np.array([147, 76, 95, 100])\n",
    "ham = np.array([98, 0, 0, 2])\n",
    "emma2 = np.array([117, 76, 123])\n",
    "pers2 = np.array([41, 20, 64])\n",
    "sense2 = np.array([76, 95, 100])\n",
    "ham2 = np.array([ 0, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883962058385787 0.9488339732466108 0.8663867983860001\n"
     ]
    }
   ],
   "source": [
    "cos_emma_pers = emma.dot(pers)/(np.linalg.norm(emma)*np.linalg.norm(pers))\n",
    "cos_emma_sense = emma.dot(sense)/(np.linalg.norm(emma)*np.linalg.norm(sense))\n",
    "cos_emma_ham = emma.dot(ham)/(np.linalg.norm(emma)*np.linalg.norm(ham))\n",
    "print(cos_emma_pers, cos_emma_sense, cos_emma_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = np.log(np.array([313, 117, 76, 123]))\n",
    "lpers = np.log(np.array([170, 41, 20, 64]))\n",
    "lsense = np.log(np.array([147, 76, 95, 100]))\n",
    "lham = np.log(np.array([98, 1, 1, 3]))\n",
    "lemma2 = np.log(np.array([117, 76, 123]))\n",
    "lpers2 = np.log(np.array([41, 20, 64]))\n",
    "lsense2 = np.log(np.array([76, 95, 100]))\n",
    "lham2 = np.log(np.array([ 1, 1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9957010464474441 0.9975042196776077 0.6791002467962006\n"
     ]
    }
   ],
   "source": [
    "cos_emma_pers = lemma.dot(lpers)/(np.linalg.norm(lemma)*np.linalg.norm(lpers))\n",
    "cos_emma_sense = lemma.dot(lsense)/(np.linalg.norm(lemma)*np.linalg.norm(lsense))\n",
    "cos_emma_ham = lemma.dot(lham)/(np.linalg.norm(lemma)*np.linalg.norm(lham))\n",
    "print(cos_emma_pers, cos_emma_sense, cos_emma_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961343253469099 0.9982561358570466 0.5987663172016887\n"
     ]
    }
   ],
   "source": [
    "cos_emma2_pers2 = lemma2.dot(lpers2)/(np.linalg.norm(lemma2)*np.linalg.norm(lpers2))\n",
    "cos_emma2_sense2 = lemma2.dot(lsense2)/(np.linalg.norm(lemma2)*np.linalg.norm(lsense2))\n",
    "cos_emma2_ham2 = lemma2.dot(lham2)/(np.linalg.norm(lemma2)*np.linalg.norm(lham2))\n",
    "print(cos_emma2_pers2, cos_emma2_sense2, cos_emma2_ham2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, -1, 2, 0], [-2, 0, 3, 1], [-1, 2, 0, 3]], dtype=np.float32)\n",
    "X = np.array((2, -1, -2, 3), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-7.],\n",
       "       [ 5.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape((1, 4))\n",
    "A@X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = np.arange(12)\n",
    "np.random.shuffle(uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng()\n",
    "arr = np.arange(10)\n",
    "rng.shuffle(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.arange(12).reshape((4, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
